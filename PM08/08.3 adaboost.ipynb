{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# AdaBoost\n",
    "\n",
    "revision: dcfbda7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# @formatter:off\n",
    "# PREAMBLE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from mlis.arrays import asinput, aslabel\n",
    "%matplotlib inline\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "sns.set_style(\"ticks\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# @formatter:on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load rock types data set\n",
    "# there is no need to normalize the data when using decision trees\n",
    "df = pd.read_csv('rocktypes.csv', sep=' ')\n",
    "df['label'] = df['type'].apply(lambda string: -1 if string == 'sand' else +1)\n",
    "sns.lmplot(x='impedance', y='velocity', hue='type', data=df, fit_reg=False)\n",
    "\n",
    "\n",
    "# Plotting decision regions\n",
    "def plot_desicion_boundary(X, y, clf):\n",
    "    x_min, x_max = X[:, 0].min(), X[:, 0].max()\n",
    "    y_min, y_max = X[:, 1].min(), X[:, 1].max()\n",
    "    x_enlarge = (x_max - x_min) * 0.1\n",
    "    y_enlarge = (y_max - y_min) * 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min - x_enlarge, x_max + x_enlarge, 300),\n",
    "                         np.linspace(y_min - y_enlarge, y_max + y_enlarge, 300))\n",
    "    XX = np.c_[xx.ravel(), yy.ravel()]\n",
    "    Z = clf(XX).reshape(xx.shape)\n",
    "    cmap = sns.diverging_palette(275, 10, as_cmap=True)\n",
    "    plt.contourf(xx, yy, Z, alpha=.2, cmap=cmap, levels=np.linspace(Z.min(), Z.max(), 20))\n",
    "    plt.contour(xx, yy, Z, levels=[0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# we will not implement a decision tree regressor again, but use the one from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# fits a decision tree stump\n",
    "def stump_fit(X, y, w=None):\n",
    "    h = DecisionTreeClassifier(max_depth=1)\n",
    "    h.fit(X, y, sample_weight=w)\n",
    "    predict = lambda t: h.predict(t)\n",
    "    return predict\n",
    "\n",
    "\n",
    "# load data\n",
    "X = asinput(df[['impedance', 'velocity']])\n",
    "y = aslabel(df['label'])\n",
    "\n",
    "# fit a decision tree regressor\n",
    "stump = stump_fit(X, y)\n",
    "\n",
    "# plot results\n",
    "sns.lmplot(x='impedance', y='velocity', hue='type', data=df, fit_reg=False)\n",
    "plot_desicion_boundary(X, y, stump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Implement the AdaBoost algorithm as described in the lecture notes.\n",
    "Plot the decision boundary for $T \\in \\{10, 50, 100, 1000 \\}$."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}