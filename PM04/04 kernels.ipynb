{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Kernels\n",
    "\n",
    "revision: dcfbda7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# @formatter:off\n",
    "# PREAMBLE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.optimize import check_grad\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "sns.set_style(\"ticks\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# @formatter:on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv('energy.csv', sep=' ')\n",
    "# normalize\n",
    "df['temp normalized'] = 2 * (df['temp'] - df['temp'].min()) / (df['temp'].max() - df['temp'].min()) - 1\n",
    "sns.lmplot(x='temp normalized', y='energy', data=df, fit_reg=False)\n",
    "\n",
    "# load the data\n",
    "X = df['temp normalized'].values.reshape((-1, 1))\n",
    "y = df['energy'].values\n",
    "m, n = X.shape\n",
    "\n",
    "print(f'X.shape = {X.shape}')\n",
    "print(f'y.shape = {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, we create a function that calculates squared exponential kernel, i.e.\n",
    "$$\n",
    "\tk(x,z) = \\exp \\Big( -\\frac{ \\lVert x-z \\rVert^2}{2\\sigma^2} \\Big)\n",
    "$$\n",
    "We do this is two steps. First, we create function `sq_dist(X, Z)` which calculates the squared euclidean distance $\\lVert x-z \\rVert^2$ between all pairs of inputs\n",
    "$$\n",
    "\tX = \\begin{bmatrix}\n",
    "\t\t~-~ \\vec{x}_1^{\\intercal} ~-~~ \\\\\n",
    "\t\t~-~ \\vec{x}_2^{\\intercal} ~-~~ \\\\\n",
    "\t\t\\vdots                                       \\\\\n",
    "\t\t~-~ \\vec{x}_m^{\\intercal} ~-~~ \\\\\n",
    "\t\\end{bmatrix}\n",
    "\\quad\\text{and}\\quad\n",
    "\tZ = \\begin{bmatrix}\n",
    "\t\t~-~ \\vec{x}_1^{\\intercal} ~-~~ \\\\\n",
    "\t\t~-~ \\vec{x}_2^{\\intercal} ~-~~ \\\\\n",
    "\t\t\\vdots                                       \\\\\n",
    "\t\t~-~ \\vec{x}_l^{\\intercal} ~-~~ \\\\\n",
    "\t\\end{bmatrix}\n",
    "$$\n",
    "Notice, that both design matrices can have a different number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Open kernels.py and implement the function sq_dist\n",
    "\n",
    "from mlis.kernels.kernels import sq_dist\n",
    "\n",
    "X = np.array([[1, 2, -1], [3, 2, 1]])\n",
    "Z = np.array([[5, 1, 5]])\n",
    "# test shape\n",
    "np.testing.assert_array_equal(sq_dist(X, Z).shape, (2, 1))\n",
    "np.testing.assert_array_almost_equal(sq_dist(X, Z), [[53], [21]], decimal=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now implement squared exponential kernel:\n",
    "$$\n",
    "\tk(x,z) = \\exp \\Big( -\\frac{\\text{sq_dist}(x,z)}{2\\sigma^2} \\Big)\n",
    "$$\n",
    "\n",
    "The function `sq_exp(X,Z,sigma)` should return the kernel matrix $K$ with $K_{ij}=k(x_i,z_j)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Open kernels.py and implement the function sq_exp\n",
    "\n",
    "from mlis.kernels.kernels import sq_exp\n",
    "\n",
    "sigma = 10\n",
    "X = np.array([[1, 2, -1], [3, 2, 1]])\n",
    "Z = np.array([[5, 1, 5]])\n",
    "# test shape\n",
    "np.testing.assert_array_equal(sq_exp(X, Z, sigma).shape, (2, 1))\n",
    "np.testing.assert_array_almost_equal(sq_exp(X, Z, sigma), [[0.767], [0.9]], decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Implement kernel ridge regression algorithm. It has a close form solution, which is\n",
    "$$\n",
    "\\alpha^\\star = (K+\\lambda I)^{-1} y,\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Open kernel_ridge_regression.py and implement the function kernel_ridge\n",
    "\n",
    "from mlis.kernels.kernel_ridge_regression import kernel_ridge\n",
    "\n",
    "sigma = 10\n",
    "lam = 1\n",
    "X = np.array([[1, 2, -1], [3, 2, 1]])\n",
    "Z = np.array([[1, 1, -1], [2, -2, -1], [.1, -3, 1]])\n",
    "y = np.array([1, 2])\n",
    "h = kernel_ridge(X, y, sigma, lam)\n",
    "\n",
    "np.testing.assert_array_almost_equal(h(Z), [0.97, 0.913, 0.858], decimal=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_fit(h, ax=None):\n",
    "    x = np.linspace(df['temp normalized'].min(), df['temp normalized'].max(), 100).reshape((-1, 1))\n",
    "    y = np.squeeze(h(x))\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    sns.scatterplot(ax=ax, x='temp normalized', y='energy', data=df)\n",
    "    ylim = ax.get_ylim()\n",
    "    ax.plot(x, y, 'k', label='Prediction')\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "\n",
    "# load the data\n",
    "X = df['temp normalized'].values.reshape((-1, 1))\n",
    "y = df['energy'].values\n",
    "\n",
    "plot_fit(kernel_ridge(X, y, sigma=10, lam=1e-6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Reproduce figure 5.1 on page 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sigmas = [0.1, 1, 10]\n",
    "lambdas = [1e-10, 0.1, 1]\n",
    "\n",
    "fig, axs = plt.subplots(len(sigmas), len(lambdas), figsize=(15, 15))\n",
    "for i, sigma in enumerate(sigmas):\n",
    "    for j, lam in enumerate(lambdas):\n",
    "        plot_fit(kernel_ridge(X, y, sigma, lam), ax=axs[i, j])\n",
    "        axs[i, j].set_title(f'$\\sigma={sigma}$\\t$\\lambda={lam}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Kernel Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_csv('rocktypes.csv', sep=' ')\n",
    "df['label'] = df['type'].apply(lambda string: -1 if string == 'sand' else +1)\n",
    "\n",
    "\n",
    "def plot_fit(h=None, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    sns.scatterplot(ax=ax, x='impedance', y='velocity', hue='type', data=df, palette=dict(sand='orange', shale='gray'))\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    scaler = preprocessing.StandardScaler().fit(df[['impedance', 'velocity']].values)\n",
    "    if h:\n",
    "        grid = 150\n",
    "        xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], grid), np.linspace(ylim[0], ylim[1], grid))\n",
    "        XY = np.array([np.ravel(xx), np.ravel(yy)]).T\n",
    "        XY = scaler.transform(XY)\n",
    "        P = h(XY).reshape(grid, grid)\n",
    "        cn = ax.contour(xx, yy, P, colors='k', levels=10)\n",
    "        ax.clabel(cn, inline=1, fontsize=10)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "\n",
    "plot_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Implement the regularized kernlized logistic regression objective, give by\n",
    "\n",
    "$$\n",
    "J(\\alpha) = \\frac{1}{m}\\sum_{i=1}^m  \\log \\big(1 + \\exp\\big(-y \\cdot \\sum_{j=1}^{m} \\alpha_j k(x_j,x_j)\\big) \\big) + \\lambda \\alpha^{\\intercal}K\\alpha\n",
    "$$\n",
    "\n",
    "using the squared exponential kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Open kernel_logistic_regression.py and implement the function J\n",
    "\n",
    "from mlis.kernels.kernel_logistic_regression import J\n",
    "\n",
    "sigma = 10\n",
    "lam = 1\n",
    "X = np.array([[1, 2, -1], [3, 2, 1]])\n",
    "α = np.array([1, -1])\n",
    "y = np.array([1, 2])\n",
    "\n",
    "np.testing.assert_array_almost_equal(J(α, X, y, sigma, lam), 0.782, decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Implement the gradient of the regularized kernelized logistic regression objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Open kernel_logistic_regression.py and implement the function dJ\n",
    "\n",
    "from mlis.kernels.kernel_logistic_regression import dJ\n",
    "\n",
    "sigma = 10\n",
    "lam = 1\n",
    "X = np.array([[1, 2, -1], [3, 2, 1]])\n",
    "α = np.array([1, -1])\n",
    "y = np.array([1, 2])\n",
    "\n",
    "np.testing.assert_allclose(check_grad(J, dJ, α, X, y, sigma, lam), 0.0, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Open kernel_logistic_regression.py and implement the function kernel_lr\n",
    "\n",
    "from mlis.kernels.kernel_logistic_regression import kernel_lr\n",
    "\n",
    "sigma = 10\n",
    "lam = 1\n",
    "X = np.array([[1, 2, -1], [3, 2, 1]])\n",
    "Z = np.array([[1, 1, -1], [2, -2, -1], [.1, -3, 1]])\n",
    "y = np.array([1, 2])\n",
    "h = kernel_lr(X, y, sigma, lam)\n",
    "np.testing.assert_array_almost_equal(h(Z), [0.28, 0.262, 0.246], decimal=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = df[['impedance', 'velocity']].values\n",
    "y = df['type'].apply(lambda string: -1 if string == 'sand' else +1).values\n",
    "# normalize data using scipy\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "\n",
    "h = kernel_lr(X, y, sigma=0.5, lam=0.01)\n",
    "plot_fit(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Reproduce figure 5.2 on page 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sigmas = [0.1, .3, .5, 1]\n",
    "lambdas = [1e-10, 0.1, 1]\n",
    "\n",
    "fig, axs = plt.subplots(len(sigmas), len(lambdas), figsize=(15, 15))\n",
    "for i, sigma in enumerate(sigmas):\n",
    "    for j, lam in enumerate(lambdas):\n",
    "        plot_fit(kernel_lr(X, y, sigma, lam), ax=axs[i, j])\n",
    "        axs[i, j].set_title(f'$\\sigma={sigma}$\\t$\\lambda={lam}$')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}