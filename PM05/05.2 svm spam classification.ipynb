{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Support Vector Machine Spam Classification\n",
    "\n",
    "revision: dcfbda7\n",
    "\n",
    "Many email services today provide spam filters that are able to classify emails\n",
    "into spam and non-spam email with high accuracy. In this part of the exercise,\n",
    "you will use SVMs to build your own spam filter. You will be training a classifier to classify whether a given email, $x$, is spam ($y = 1$) or non-spam ($y = 0$). In particular, you need to convert each\n",
    "email into a feature vector $x \\in \\mathbb{R}^n$. The following parts of the exercise will walk you through how such a feature vector can be constructed from an email.\n",
    "\n",
    "\n",
    "*References:* These exercises are based on the Stanford Machine Learning Course [CS229](http://cs229.stanford.edu) of Andrew Ng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# @formatter:off\n",
    "# PREAMBLE\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as si\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "sns.set_style(\"ticks\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# @formatter:on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocessing Emails\n",
    "\n",
    "Before starting on a machine learning task, it is usually insightful to\n",
    "take a look at examples from the dataset.\n",
    "\n",
    "```\n",
    "> Anyone knows how much it costs to host a web portal ?\n",
    ">\n",
    "Well, it depends on how many visitors youre expecting. This can be\n",
    "anywhere from less than 10 bucks a month to a couple of $100. You\n",
    "should checkout http://www.rackspace.com/ or perhaps Amazon EC2 if\n",
    "youre running something big..\n",
    "To unsubscribe yourself from this mailing list, send an email to:\n",
    "groupname-unsubscribe@egroups.com\n",
    "```\n",
    "\n",
    "This sample email contains a URL, an email address (at the end), numbers, and dollar\n",
    "amounts. While many emails would contain similar types of entities (e.g.,\n",
    "numbers, other URLs, or other email addresses), the specific entities (e.g.,\n",
    "the specific URL or specific dollar amount) will be different in almost every\n",
    "email. Therefore, one method often employed in processing emails is to\n",
    "“normalize” these values, so that all URLs are treated the same, all numbers\n",
    "are treated the same, etc. For example, we could replace each URL in the\n",
    "email with the unique string “httpaddr” to indicate that a URL was present.\n",
    "This has the effect of letting the spam classifier make a classification decision\n",
    "based on whether any URL was present, rather than whether a specific URL\n",
    "was present. This typically improves the performance of a spam classifier,\n",
    "since spammers often randomize the URLs, and thus the odds of seeing any\n",
    "particular URL again in a new piece of spam is very small.\n",
    "\n",
    "In `normalizeEmail`, we have implemented the following email preprocessing\n",
    "and normalization steps:\n",
    "\n",
    "* **Lower-casing**: The entire email is converted into lower case, so\n",
    "that captialization is ignored (e.g., `IndIcaTE` is treated the same as\n",
    "`Indicate`).\n",
    "\n",
    "* **Stripping HTML**: All HTML tags are removed from the emails.\n",
    "Many emails often come with HTML formatting; we remove all the\n",
    "HTML tags, so that only the content remains.\n",
    "\n",
    "* **Normalizing URLs**: All URLs are replaced with the text \"`httpaddr`\".\n",
    "\n",
    "* **Normalizing Email Addresses**: All email addresses are replaced\n",
    "with the text \"`emailaddr`\".\n",
    "\n",
    "* **Normalizing Numbers**: All numbers are replaced with the text \"`number`\".\n",
    "\n",
    "* **Normalizing Dollars**: All dollar signs ($) are replaced with the text \"`dollar`\".\n",
    "\n",
    "* **Word Stemming**: Words are reduced to their stemmed form. For example,\n",
    "\"discount\", “discounts”, “discounted” and “discounting” are all\n",
    "replaced with “discount”. Sometimes, the Stemmer actually strips off\n",
    "additional characters from the end, so “include”, “includes”, “included”,\n",
    "and “including” are all replaced with “includ”.\n",
    "\n",
    "* **Removal of non-words**: Non-words and punctuation have been removed.\n",
    "All white spaces (tabs, newlines, spaces) have all been trimmed\n",
    "to a single space character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalizeEmail(email_contents):\n",
    "    # the result\n",
    "    normalized = []\n",
    "\n",
    "    # lower case\n",
    "    email_contents = email_contents.lower()\n",
    "\n",
    "    # strip all HTML\n",
    "    email_contents = re.sub('<[^<>]+>', ' ', email_contents)\n",
    "\n",
    "    # Handle numbers\n",
    "    email_contents = re.sub('[0-9]+', 'number', email_contents)\n",
    "\n",
    "    # Handle URLS\n",
    "    email_contents = re.sub('(http|https)://[^\\s]*', 'httpaddr', email_contents)\n",
    "\n",
    "    # Handle email addresses\n",
    "    email_contents = re.sub('[^\\s]+@[^\\s]+', 'emailaddr', email_contents)\n",
    "\n",
    "    # handle $ sign\n",
    "    email_contents = re.sub('[$]+', 'dollar', email_contents)\n",
    "\n",
    "    # tokenize\n",
    "    tokens = re.split('[ ' +\n",
    "                      re.escape(\"@$/#.-:&*+=[]?!(){},'\\\">_<;%\") + ']',\n",
    "                      email_contents)\n",
    "\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    for token in tokens:\n",
    "        token = re.sub('[^a-zA-Z0-9]', '', token)\n",
    "        token = stemmer.stem(token.strip())\n",
    "        if len(token) > 0:\n",
    "            normalized.append(token)\n",
    "\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The result of these preprocessing steps is\n",
    "```\n",
    "anyon know how much it cost to host a web portal well it depend on how \n",
    "mani visitor your expect thi can be anywher from less than number buck \n",
    "a month to a coupl of dollarnumb you should checkout httpaddr or perhap \n",
    "amazon ecnumb if your run someth big to unsubscrib yourself from thi \n",
    "mail list send an email to emailaddr\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_email = \"\"\"> Anyone knows how much it costs to host a web portal ?\n",
    ">\n",
    "Well, it depends on how many visitors youre expecting. This can be \n",
    "anywhere from less than 10 bucks a month to a couple of $100. You \n",
    "should checkout http://www.rackspace.com/ or perhaps Amazon EC2 if \n",
    "youre running something big..\n",
    "\n",
    "To unsubscribe yourself from this mailing list, send an email to: \n",
    "groupname-unsubscribe@egroups.com\"\"\"\n",
    "\n",
    "normalized_sample = normalizeEmail(sample_email)\n",
    "print(\" \".join(normalized_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "While preprocessing has left word fragments and non-words, this form turns out to be\n",
    "much easier to work with for performing feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Vocabulary List\n",
    "\n",
    "After preprocessing the emails, we have a list of words for\n",
    "each email. The next step is to choose which words we would like to use in\n",
    "our classifier and which we would want to leave out. \n",
    "\n",
    "For this exercise, we have chosen only the most frequently occuring words\n",
    "as our set of words considered (the vocabulary list). Since words that occur\n",
    "rarely in the training set are only in a few emails, they might cause the\n",
    "model to overfit our training set. The complete vocabulary list is in the file\n",
    "`vocab.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read vocab file\n",
    "def loadVocabulary():\n",
    "    return pd.read_csv('vocab.txt', sep='\\t', header=None).values\n",
    "\n",
    "\n",
    "vocabList = loadVocabulary()\n",
    "print(vocabList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Our vocabulary list was selected by choosing all words which occur at least a 100 times in the spam corpus,\n",
    "resulting in a list of 1899 words. In practice, a vocabulary list with about 10,000 to 50,000 words is often used.\n",
    "\n",
    "Given the vocabulary list, we can now map each word in the preprocessed emails into a list of word indices that contains the index of the word in the vocabulary list which results in \n",
    "```\n",
    "[86, 916, 794, 1077, 883, 370, 1699, 790, 1822, 1831, 883, 431, 1171, 794, 1002, 1895, 592, 1676, 238, 688, 945, 1663, 1120, 1062, 1699, 375, 1162, 479, 799, 1182, 1237, 1440, 1547, 181, 1699, 1758, 1896, 688, 1676, 992, 961, 1477, 71, 530, 1699, 531]\n",
    "```\n",
    "as the vocabulary index representation of the sample email. \n",
    "\n",
    "Your task now is to complete the code in `processEmail` to perform this mapping. You should look up the word in the vocabulary list `vocabList` and find if the word exists in the vocabulary list. If the word\n",
    "exists, you should add the index of the word into the word indices variable. If the word does not exist, and is therefore not in the vocabulary, you can skip the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def processEmail(email):\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(processEmail(sample_email))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extracting Features from Emails\n",
    "\n",
    "You will now implement the feature extraction that converts each email into\n",
    "a vector in $\\mathbb{R}^d$. For this exercise, you will be using $d = \\# \\text{words in vocabulary\n",
    "list}$. Specifically, the feature $x_i \\in \\{0, 1\\}$ for an email corresponds to whether\n",
    "the $i$-th word in the dictionary occurs in the email. That is, $x_i = 1$ if the $i$-th\n",
    "word is in the email and $x_i = 0$ if the $i$-th word is not present in the email.\n",
    "\n",
    "You should see that the feature vector had length 1899 and 44 non-zero entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def emailFeatures(email):\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_feature = emailFeatures(sample_email)\n",
    "print(f\"length: {len(sample_feature)} non-zeros: {np.count_nonzero(sample_feature)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training SVM for Spam Classification\n",
    "\n",
    "After you have completed the feature extraction functions, the next step is to load a preprocessed training dataset that will be used to train a SVM classifier. \n",
    "\n",
    "The training dataset contains 4000 training examples of spam\n",
    "and non-spam email, while the test dataset contains 1000 test examples. Each\n",
    "original email was processed using the `emailFeatures` function and converted into a vector \n",
    "$x_{i} \\in \\mathbb{R}^{1899}$.\n",
    "\n",
    "After loading the dataset we will proceed to train a SVM to\n",
    "classify between spam ($y = 1$) and non-spam ($y = 0$) emails. Once the\n",
    "training completes, you should see that the classifier gets a training accuracy\n",
    "of about $99.8\\%$ and a test accuracy of about $98.9\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    data = si.loadmat('spamTrain.mat')\n",
    "    train = {'X': data['X'], 'y': data['y'].flatten()}\n",
    "\n",
    "    data = si.loadmat('spamTest.mat')\n",
    "    test = {'X': data['Xtest'], 'y': data['ytest'].flatten()}\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "train, test = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# train support vector machine\n",
    "svm = SVC(C=0.1, kernel='linear').fit(train['X'], train['y'])\n",
    "\n",
    "print(\"Training set accuracy: %.1f%%\" % (svm.score(train['X'], train['y']) * 100))\n",
    "print(\"Test set accuracy: %.1f%%\" % (svm.score(test['X'], test['y']) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Top Predictors for Spam\n",
    "\n",
    "To better understand how the spam classifier works, we can inspect the\n",
    "parameters to see which words the classifier thinks are the most predictive\n",
    "of spam. \n",
    "\n",
    "The next step finds the parameters with the largest\n",
    "positive values in the classifier and displays the corresponding words. Thus, if an email contains words such as “guarantee”, “remove”, “dollar”,\n",
    "and “price” it is likely to be\n",
    "classified as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "topidx = np.argsort(svm.coef_[0]).tolist()[::-1]\n",
    "vdict = dict(loadVocabulary())\n",
    "top = list(map(lambda idx: vdict[idx + 1], topidx))\n",
    "print(top[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test on some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fileAsString(filename):\n",
    "    with open(filename, 'r') as fh:\n",
    "        return fh.read()\n",
    "\n",
    "\n",
    "sample1 = fileAsString('spamSample1.txt')\n",
    "sample3 = fileAsString('emailSample1.txt')\n",
    "sample4 = fileAsString('emailSample2.txt')\n",
    "\n",
    "# Test the support vector machine on the samples (sample1, sample3, sample4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "features = emailFeatures(sample3)\n",
    "predict = svm.predict(features.reshape((1, -1))).squeeze()\n",
    "print(sample3)\n",
    "print(\"The email was classified as %s\" % (\"SPAM\" if predict == 1 else \"NOT SPAM\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}